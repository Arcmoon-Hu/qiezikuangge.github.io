{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T13:01:28.862920Z",
     "start_time": "2019-11-20T13:01:21.195091Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not use moxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconada\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "D:\\Anaconada\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "D:\\Anaconada\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "D:\\Anaconada\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "D:\\Anaconada\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "D:\\Anaconada\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "usage: ipykernel_launcher.py [-h] --input_dir INPUT_DIR --output_train_dir\n",
      "                             OUTPUT_TRAIN_DIR --output_val_dir OUTPUT_VAL_DIR\n",
      "ipykernel_launcher.py: error: the following arguments are required: --input_dir, --output_train_dir, --output_val_dir\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconada\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3334: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "#数据预处理\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "数据集准备脚本\n",
    "\"\"\"\n",
    "import os\n",
    "import codecs\n",
    "import shutil\n",
    "try:\n",
    "    import moxing as mox\n",
    "except:\n",
    "    print('not use moxing')\n",
    "from glob import glob\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "\n",
    "def prepare_data_on_modelarts(args):\n",
    "    \"\"\"\n",
    "    如果数据集存储在OBS，则需要将OBS上的数据拷贝到 ModelArts 中\n",
    "    \"\"\"\n",
    "    # Create some local cache directories used for transfer data between local path and OBS path\n",
    "    if not args.data_url.startswith('s3://'):\n",
    "        args.data_local = args.data_url\n",
    "    else:\n",
    "        args.data_local = os.path.join(args.local_data_root, 'train_val')\n",
    "        if not os.path.exists(args.data_local):\n",
    "            mox.file.copy_parallel(args.data_url, args.data_local)\n",
    "        else:\n",
    "            print('args.data_local: %s is already exist, skip copy' % args.data_local)\n",
    "\n",
    "    if not args.train_url.startswith('s3://'):\n",
    "        args.train_local = args.train_url\n",
    "    else:\n",
    "        args.train_local = os.path.join(args.local_data_root, 'model_snapshots')\n",
    "        if not os.path.exists(args.train_local):\n",
    "            os.mkdir(args.train_local)\n",
    "\n",
    "    if not args.test_data_url.startswith('s3://'):\n",
    "        args.test_data_local = args.test_data_url\n",
    "    else:\n",
    "        args.test_data_local = os.path.join(args.local_data_root, 'test_data/')\n",
    "        if not os.path.exists(args.test_data_local):\n",
    "            mox.file.copy_parallel(args.test_data_url, args.test_data_local)\n",
    "        else:\n",
    "            print('args.test_data_local: %s is already exist, skip copy' % args.test_data_local)\n",
    "\n",
    "    args.tmp = os.path.join(args.local_data_root, 'tmp')\n",
    "    if not os.path.exists(args.tmp):\n",
    "        os.mkdir(args.tmp)\n",
    "\n",
    "    return args\n",
    "\n",
    "\n",
    "def split_train_val(input_dir, output_train_dir, output_val_dir):\n",
    "    \"\"\"\n",
    "    大赛发布的公开数据集是所有图片和标签txt都在一个目录中的格式\n",
    "    如果需要使用 torch.utils.data.DataLoader 来加载数据，则需要将数据的存储格式做如下改变：\n",
    "    1）划分训练集和验证集，分别存放为 train 和 val 目录；\n",
    "    2）train 和 val 目录下有按类别存放的子目录，子目录中都是同一个类的图片\n",
    "    本函数就是实现如上功能，建议先在自己的机器上运行本函数，然后将处理好的数据上传到OBS\n",
    "    \"\"\"\n",
    "    if not os.path.exists(input_dir):\n",
    "        print(input_dir, 'is not exist')\n",
    "        return\n",
    "\n",
    "    # 1. 检查图片和标签的一一对应\n",
    "    label_file_paths = glob(os.path.join(input_dir, '*.txt'))\n",
    "    valid_img_names = []\n",
    "    valid_labels = []\n",
    "    for file_path in label_file_paths:\n",
    "        with codecs.open(file_path, 'r', 'utf-8') as f:\n",
    "            line = f.readline()\n",
    "        line_split = line.strip().split(', ')\n",
    "        img_name = line_split[0]\n",
    "        label_id = line_split[1]\n",
    "        if os.path.exists(os.path.join(input_dir, img_name)):\n",
    "            valid_img_names.append(img_name)\n",
    "            valid_labels.append(int(label_id))\n",
    "        else:\n",
    "            print('error', img_name, 'is not exist')\n",
    "\n",
    "    # 2. 使用 StratifiedShuffleSplit 划分训练集和验证集，可保证划分后各类别的占比保持一致\n",
    "    # TODO，数据集划分方式可根据您的需要自行调整\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=500, random_state=0)\n",
    "    sps = sss.split(valid_img_names, valid_labels)\n",
    "    for sp in sps:\n",
    "        train_index, val_index = sp\n",
    "\n",
    "    label_id_name_dict = \\\n",
    "        {\n",
    "            \"0\": \"工艺品/仿唐三彩\",\n",
    "            \"1\": \"工艺品/仿宋木叶盏\",\n",
    "            \"2\": \"工艺品/布贴绣\",\n",
    "            \"3\": \"工艺品/景泰蓝\",\n",
    "            \"4\": \"工艺品/木马勺脸谱\",\n",
    "            \"5\": \"工艺品/柳编\",\n",
    "            \"6\": \"工艺品/葡萄花鸟纹银香囊\",\n",
    "            \"7\": \"工艺品/西安剪纸\",\n",
    "            \"8\": \"工艺品/陕历博唐妞系列\",\n",
    "            \"9\": \"景点/关中书院\",\n",
    "            \"10\": \"景点/兵马俑\",\n",
    "            \"11\": \"景点/南五台\",\n",
    "            \"12\": \"景点/大兴善寺\",\n",
    "            \"13\": \"景点/大观楼\",\n",
    "            \"14\": \"景点/大雁塔\",\n",
    "            \"15\": \"景点/小雁塔\",\n",
    "            \"16\": \"景点/未央宫城墙遗址\",\n",
    "            \"17\": \"景点/水陆庵壁塑\",\n",
    "            \"18\": \"景点/汉长安城遗址\",\n",
    "            \"19\": \"景点/西安城墙\",\n",
    "            \"20\": \"景点/钟楼\",\n",
    "            \"21\": \"景点/长安华严寺\",\n",
    "            \"22\": \"景点/阿房宫遗址\",\n",
    "            \"23\": \"民俗/唢呐\",\n",
    "            \"24\": \"民俗/皮影\",\n",
    "            \"25\": \"特产/临潼火晶柿子\",\n",
    "            \"26\": \"特产/山茱萸\",\n",
    "            \"27\": \"特产/玉器\",\n",
    "            \"28\": \"特产/阎良甜瓜\",\n",
    "            \"29\": \"特产/陕北红小豆\",\n",
    "            \"30\": \"特产/高陵冬枣\",\n",
    "            \"31\": \"美食/八宝玫瑰镜糕\",\n",
    "            \"32\": \"美食/凉皮\",\n",
    "            \"33\": \"美食/凉鱼\",\n",
    "            \"34\": \"美食/德懋恭水晶饼\",\n",
    "            \"35\": \"美食/搅团\",\n",
    "            \"36\": \"美食/枸杞炖银耳\",\n",
    "            \"37\": \"美食/柿子饼\",\n",
    "            \"38\": \"美食/浆水面\",\n",
    "            \"39\": \"美食/灌汤包\",\n",
    "            \"40\": \"美食/烧肘子\",\n",
    "            \"41\": \"美食/石子饼\",\n",
    "            \"42\": \"美食/神仙粉\",\n",
    "            \"43\": \"美食/粉汤羊血\",\n",
    "            \"44\": \"美食/羊肉泡馍\",\n",
    "            \"45\": \"美食/肉夹馍\",\n",
    "            \"46\": \"美食/荞面饸饹\",\n",
    "            \"47\": \"美食/菠菜面\",\n",
    "            \"48\": \"美食/蜂蜜凉粽子\",\n",
    "            \"49\": \"美食/蜜饯张口酥饺\",\n",
    "            \"50\": \"美食/西安油茶\",\n",
    "            \"51\": \"美食/贵妃鸡翅\",\n",
    "            \"52\": \"美食/醪糟\",\n",
    "            \"53\": \"美食/金线油塔\"\n",
    "        }\n",
    "\n",
    "    # 3. 创建 output_train_dir 目录下的所有标签名子目录\n",
    "    for id in label_id_name_dict.keys():\n",
    "        if not os.path.exists(os.path.join(output_train_dir, id)):\n",
    "            os.mkdir(os.path.join(output_train_dir, id))\n",
    "\n",
    "    # 4. 将训练集图片拷贝到 output_train_dir 目录\n",
    "    for index in train_index:\n",
    "        file_path = label_file_paths[index]\n",
    "        with codecs.open(file_path, 'r', 'utf-8') as f:\n",
    "            gt_label = f.readline()\n",
    "        img_name = gt_label.split(',')[0].strip()\n",
    "        id = gt_label.split(',')[1].strip()\n",
    "        shutil.copy(os.path.join(input_dir, img_name), os.path.join(output_train_dir, id, img_name))\n",
    "\n",
    "    # 5. 创建 output_val_dir 目录下的所有标签名子目录\n",
    "    for id in label_id_name_dict.keys():\n",
    "        if not os.path.exists(os.path.join(output_val_dir, id)):\n",
    "            os.mkdir(os.path.join(output_val_dir, id))\n",
    "\n",
    "    # 6. 将验证集图片拷贝到 output_val_dir 目录\n",
    "    for index in val_index:\n",
    "        file_path = label_file_paths[index]\n",
    "        with codecs.open(file_path, 'r', 'utf-8') as f:\n",
    "            gt_label = f.readline()\n",
    "        img_name = gt_label.split(',')[0].strip()\n",
    "        id = gt_label.split(',')[1].strip()\n",
    "        shutil.copy(os.path.join(input_dir, img_name), os.path.join(output_val_dir, id, img_name))\n",
    "\n",
    "    print('total samples: %d, train samples: %d, val samples:%d'\n",
    "          % (len(valid_labels), len(train_index), len(val_index)))\n",
    "    print('end')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    import argparse\n",
    "    parser = argparse.ArgumentParser(description='data prepare')\n",
    "    parser.add_argument('--input_dir', required=True, type=str, help='input data dir')\n",
    "    parser.add_argument('--output_train_dir', required=True, type=str, help='output train data dir')\n",
    "    parser.add_argument('--output_val_dir', required=True, type=str, help='output validation data dir')\n",
    "    args = parser.parse_args()\n",
    "    if args.input_dir == '' or args.output_train_dir == '' or args.output_val_dir == '':\n",
    "        raise Exception('You must specify valid arguments')\n",
    "    if not os.path.exists(args.output_train_dir):\n",
    "        os.makedirs(args.output_train_dir)\n",
    "    if not os.path.exists(args.output_val_dir):\n",
    "        os.makedirs(args.output_val_dir)\n",
    "    split_train_val(args.input_dir, args.output_train_dir, args.output_val_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#主函数\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "基于 PyTorch resnet50 实现的图片分类代码\n",
    "原代码地址：https://github.com/pytorch/examples/blob/master/imagenet/main.py\n",
    "可以与原代码进行比较，查看需修改哪些代码才可以将其改造成可以在 ModelArts 上运行的代码\n",
    "在ModelArts Notebook中的代码运行方法：\n",
    "（0）准备数据\n",
    "大赛发布的公开数据集是所有图片和标签txt都在一个目录中的格式\n",
    "如果需要使用 torch.utils.data.DataLoader 来加载数据，则需要将数据的存储格式做如下改变：\n",
    "1）划分训练集和验证集，分别存放为 train 和 val 目录；\n",
    "2）train 和 val 目录下有按类别存放的子目录，子目录中都是同一个类的图片\n",
    "prepare_data.py中的 split_train_val 函数就是实现如上功能，建议先在自己的机器上运行该函数，然后将处理好的数据上传到OBS\n",
    "执行该函数的方法如下：\n",
    "cd {prepare_data.py所在目录}\n",
    "python prepare_data.py --input_dir '../datasets/train_data' --output_train_dir '../datasets/train_val/train' --output_val_dir '../datasets/train_val/val'\n",
    "\n",
    "（1）从零训练\n",
    "cd {main.py所在目录}\n",
    "python main.py --data_url '../datasets/train_val' --train_url '../model_snapshots' --deploy_script_path './deploy_scripts' --arch 'resnet50' --num_classes 54 --workers 4 --epochs 6 --pretrained True --seed 0\n",
    "\n",
    "（2）加载已有模型继续训练\n",
    "cd {main.py所在目录}\n",
    "python main.py --data_url '../datasets/train_val' --train_url '../model_snapshots' --deploy_script_path './deploy_scripts' --arch 'resnet50' --num_classes 54 --workers 4 --epochs 6 --seed 0 --resume '../model_snapshots/epoch_0_2.4.pth'\n",
    "\n",
    "（3）评价单个pth文件\n",
    "cd {main.py所在目录}\n",
    "python main.py --data_url '../datasets/train_val' --train_url '../model_snapshots' --arch 'resnet50' --num_classes 54 --seed 0 --eval_pth '../model_snapshots/epoch_5_8.4.pth'\n",
    "\"\"\"\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "try:\n",
    "    import moxing as mox\n",
    "except:\n",
    "    print('not use moxing')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "import torch.optim\n",
    "import torch.multiprocessing as mp\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "\n",
    "from prepare_data import prepare_data_on_modelarts\n",
    "\n",
    "model_names = sorted(name for name in models.__dict__\n",
    "    if name.islower() and not name.startswith(\"__\")\n",
    "    and callable(models.__dict__[name]))\n",
    "\n",
    "parser = argparse.ArgumentParser(description='PyTorch ImageNet Training')\n",
    "# parser.add_argument('data', metavar='DIR',\n",
    "#                     help='path to dataset')\n",
    "parser.add_argument('-a', '--arch', metavar='ARCH', required=True,\n",
    "                    choices=model_names,\n",
    "                    help='model architecture: ' +\n",
    "                        ' | '.join(model_names) +\n",
    "                        ' (default: resnet18)')\n",
    "parser.add_argument('-j', '--workers', default=4, type=int, metavar='N',\n",
    "                    help='number of data loading workers (default: 4)')\n",
    "parser.add_argument('--epochs', default=10, type=int, metavar='N',\n",
    "                    help='number of total epochs to run')\n",
    "parser.add_argument('--start_epoch', default=0, type=int, metavar='N',\n",
    "                    help='manual epoch number (useful on restarts)')\n",
    "parser.add_argument('-b', '--batch-size', default=128, type=int,\n",
    "                    metavar='N',\n",
    "                    help='mini-batch size (default: 128), this is the total '\n",
    "                         'batch size of all GPUs on the current node when '\n",
    "                         'using Data Parallel or Distributed Data Parallel')\n",
    "parser.add_argument('--lr', '--learning-rate', default=0.1, type=float,\n",
    "                    metavar='LR', help='initial learning rate', dest='lr')\n",
    "parser.add_argument('--momentum', default=0.9, type=float, metavar='M',\n",
    "                    help='momentum')\n",
    "parser.add_argument('--wd', '--weight-decay', default=1e-4, type=float,\n",
    "                    metavar='W', help='weight decay (default: 1e-4)',\n",
    "                    dest='weight_decay')\n",
    "parser.add_argument('-p', '--print_freq', default=5, type=int,\n",
    "                    metavar='N', help='print frequency (default: 10)')\n",
    "parser.add_argument('--resume', default='', type=str, metavar='PATH',\n",
    "                    help='path to latest checkpoint (default: none)')\n",
    "# parser.add_argument('-e', '--evaluate', dest='evaluate', action='store_true',\n",
    "#                     help='evaluate model on validation set')\n",
    "parser.add_argument('--eval_pth', default='', type=str,\n",
    "                    help='the *.pth model path need to be evaluated on validation set')\n",
    "parser.add_argument('--pretrained', default=False, type=bool,\n",
    "                    help='use pre-trained model or not')\n",
    "parser.add_argument('--world-size', default=-1, type=int,\n",
    "                    help='number of nodes for distributed training')\n",
    "parser.add_argument('--rank', default=-1, type=int,\n",
    "                    help='node rank for distributed training')\n",
    "parser.add_argument('--dist-url', default='tcp://224.66.41.62:23456', type=str,\n",
    "                    help='url used to set up distributed training')\n",
    "parser.add_argument('--dist-backend', default='nccl', type=str,\n",
    "                    help='distributed backend')\n",
    "parser.add_argument('--seed', default=None, type=int,\n",
    "                    help='seed for initializing training. ')\n",
    "parser.add_argument('--gpu', default=None, type=int,\n",
    "                    help='GPU id to use.')\n",
    "parser.add_argument('--multiprocessing-distributed', action='store_true',\n",
    "                    help='Use multi-processing distributed training to launch '\n",
    "                         'N processes per node, which has N GPUs. This is the '\n",
    "                         'fastest way to use PyTorch for either single node or '\n",
    "                         'multi node data parallel training')\n",
    "\n",
    "# These arguments are added for adapting ModelArts\n",
    "parser.add_argument('--num_classes', required=True, type=int, help='the num of classes which your task should classify')\n",
    "parser.add_argument('--local_data_root', default='/cache/', type=str,\n",
    "                    help='a directory used for transfer data between local path and OBS path')\n",
    "parser.add_argument('--data_url', required=True, type=str, help='the training and validation data path')\n",
    "parser.add_argument('--test_data_url', default='', type=str, help='the test data path')\n",
    "parser.add_argument('--data_local', default='', type=str, help='the training and validation data path on local')\n",
    "parser.add_argument('--test_data_local', default='', type=str, help='the test data path on local')\n",
    "parser.add_argument('--train_url', required=True, type=str, help='the path to save training outputs')\n",
    "parser.add_argument('--train_local', default='', type=str, help='the training output results on local')\n",
    "parser.add_argument('--tmp', default='', type=str, help='a temporary path on local')\n",
    "parser.add_argument('--deploy_script_path', default='', type=str,\n",
    "                    help='a path which contain config.json and customize_service.py, '\n",
    "                         'if it is set, these two scripts will be copied to {train_url}/model directory')\n",
    "best_acc1 = 0\n",
    "\n",
    "\n",
    "def main():\n",
    "    args, unknown = parser.parse_known_args()\n",
    "    args = prepare_data_on_modelarts(args)\n",
    "\n",
    "    if args.seed is not None:\n",
    "        random.seed(args.seed)\n",
    "        torch.manual_seed(args.seed)\n",
    "        cudnn.deterministic = True\n",
    "        warnings.warn('You have chosen to seed training. '\n",
    "                      'This will turn on the CUDNN deterministic setting, '\n",
    "                      'which can slow down your training considerably! '\n",
    "                      'You may see unexpected behavior when restarting '\n",
    "                      'from checkpoints.')\n",
    "\n",
    "    if args.gpu is not None:\n",
    "        warnings.warn('You have chosen a specific GPU. This will completely '\n",
    "                      'disable data parallelism.')\n",
    "\n",
    "    if args.dist_url == \"env://\" and args.world_size == -1:\n",
    "        args.world_size = int(os.environ[\"WORLD_SIZE\"])\n",
    "\n",
    "    args.distributed = args.world_size > 1 or args.multiprocessing_distributed\n",
    "\n",
    "    ngpus_per_node = torch.cuda.device_count()\n",
    "    if args.multiprocessing_distributed:\n",
    "        # Since we have ngpus_per_node processes per node, the total world_size\n",
    "        # needs to be adjusted accordingly\n",
    "        args.world_size = ngpus_per_node * args.world_size\n",
    "        # Use torch.multiprocessing.spawn to launch distributed processes: the\n",
    "        # main_worker process function\n",
    "        mp.spawn(main_worker, nprocs=ngpus_per_node, args=(ngpus_per_node, args))\n",
    "    else:\n",
    "        # Simply call main_worker function\n",
    "        main_worker(args.gpu, ngpus_per_node, args)\n",
    "\n",
    "\n",
    "def main_worker(gpu, ngpus_per_node, args):\n",
    "    global best_acc1\n",
    "    args.gpu = gpu\n",
    "\n",
    "    if args.gpu is not None:\n",
    "        print(\"Use GPU: {} for training\".format(args.gpu))\n",
    "\n",
    "    if args.distributed:\n",
    "        if args.dist_url == \"env://\" and args.rank == -1:\n",
    "            args.rank = int(os.environ[\"RANK\"])\n",
    "        if args.multiprocessing_distributed:\n",
    "            # For multiprocessing distributed training, rank needs to be the\n",
    "            # global rank among all the processes\n",
    "            args.rank = args.rank * ngpus_per_node + gpu\n",
    "        dist.init_process_group(backend=args.dist_backend, init_method=args.dist_url,\n",
    "                                world_size=args.world_size, rank=args.rank)\n",
    "    # create model\n",
    "    if args.pretrained:\n",
    "        print(\"=> using pre-trained model '{}'\".format(args.arch))\n",
    "        os.environ['TORCH_MODEL_ZOO'] = '../pre-trained_model/pytorch'\n",
    "        if not mox.file.exists('../pre-trained_model/pytorch/resnet50-19c8e357.pth'):\n",
    "            mox.file.copy('s3://ma-competitions-bj4/model_zoo/pytorch/resnet50-19c8e357.pth',\n",
    "                          '../pre-trained_model/pytorch/resnet50-19c8e357.pth')\n",
    "            print('copy pre-trained model from OBS to: %s success' %\n",
    "                  (os.path.abspath('../pre-trained_model/pytorch/resnet50-19c8e357.pth')))\n",
    "        else:\n",
    "            print('use exist pre-trained model at: %s' %\n",
    "                  (os.path.abspath('../pre-trained_model/pytorch/resnet50-19c8e357.pth')))\n",
    "        model = models.__dict__[args.arch](pretrained=True)\n",
    "    else:\n",
    "        print(\"=> creating model '{}'\".format(args.arch))\n",
    "        model = models.__dict__[args.arch]()\n",
    "\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, args.num_classes)\n",
    "\n",
    "    if args.distributed:\n",
    "        # For multiprocessing distributed, DistributedDataParallel constructor\n",
    "        # should always set the single device scope, otherwise,\n",
    "        # DistributedDataParallel will use all available devices.\n",
    "        if args.gpu is not None:\n",
    "            torch.cuda.set_device(args.gpu)\n",
    "            model.cuda(args.gpu)\n",
    "            # When using a single GPU per process and per\n",
    "            # DistributedDataParallel, we need to divide the batch size\n",
    "            # ourselves based on the total number of GPUs we have\n",
    "            args.batch_size = int(args.batch_size / ngpus_per_node)\n",
    "            args.workers = int((args.workers + ngpus_per_node - 1) / ngpus_per_node)\n",
    "            model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[args.gpu])\n",
    "        else:\n",
    "            model.cuda()\n",
    "            # DistributedDataParallel will divide and allocate batch_size to all\n",
    "            # available GPUs if device_ids are not set\n",
    "            model = torch.nn.parallel.DistributedDataParallel(model)\n",
    "    elif args.gpu is not None:\n",
    "        torch.cuda.set_device(args.gpu)\n",
    "        model = model.cuda(args.gpu)\n",
    "    else:\n",
    "        # DataParallel will divide and allocate batch_size to all available GPUs\n",
    "        if args.arch.startswith('alexnet') or args.arch.startswith('vgg'):\n",
    "            model.features = torch.nn.DataParallel(model.features)\n",
    "            model.cuda()\n",
    "        else:\n",
    "            model = torch.nn.DataParallel(model).cuda()\n",
    "\n",
    "    # define loss function (criterion) and optimizer\n",
    "    criterion = nn.CrossEntropyLoss().cuda(args.gpu)\n",
    "\n",
    "    optimizer = torch.optim.SGD(model.parameters(), args.lr,\n",
    "                                momentum=args.momentum,\n",
    "                                weight_decay=args.weight_decay)\n",
    "\n",
    "    # optionally resume from a checkpoint\n",
    "    if args.resume:\n",
    "        # if os.path.isfile(args.resume):\n",
    "        if mox.file.exists(args.resume) and (not mox.file.is_directory(args.resume)):\n",
    "            if args.resume.startswith('s3://'):\n",
    "                restore_model_name = args.resume.rsplit('/', 1)[1]\n",
    "                mox.file.copy(args.resume, '/cache/tmp/' + restore_model_name)\n",
    "                args.resume = '/cache/tmp/' + restore_model_name\n",
    "            print(\"=> loading checkpoint '{}'\".format(args.resume))\n",
    "            if args.gpu is None:\n",
    "                checkpoint = torch.load(args.resume)\n",
    "            else:\n",
    "                # Map model to be loaded to specified single gpu.\n",
    "                loc = 'cuda:{}'.format(args.gpu)\n",
    "                checkpoint = torch.load(args.resume, map_location=loc)\n",
    "            if args.resume.startswith('/cache/tmp/'):\n",
    "                os.remove(args.resume)\n",
    "\n",
    "            args.start_epoch = checkpoint['epoch']\n",
    "            best_acc1 = checkpoint['best_acc1']\n",
    "            if args.gpu is not None:\n",
    "                # best_acc1 may be from a checkpoint from a different GPU\n",
    "                best_acc1 = best_acc1.to(args.gpu)\n",
    "            model.load_state_dict(checkpoint['state_dict'])\n",
    "            optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "            print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                  .format(args.resume, checkpoint['epoch']))\n",
    "        else:\n",
    "            print(\"=> no checkpoint found at '{}'\".format(args.resume))\n",
    "\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "    # Data loading code\n",
    "    traindir = os.path.join(args.data_local, 'train')\n",
    "    valdir = os.path.join(args.data_local, 'val')\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "\n",
    "    train_dataset = datasets.ImageFolder(\n",
    "        traindir,\n",
    "        transforms.Compose([\n",
    "            transforms.RandomResizedCrop(224),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]))\n",
    "\n",
    "    if args.distributed:\n",
    "        train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset)\n",
    "    else:\n",
    "        train_sampler = None\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=args.batch_size, shuffle=(train_sampler is None),\n",
    "        num_workers=args.workers, pin_memory=True, sampler=train_sampler)\n",
    "\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        datasets.ImageFolder(valdir, transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ])),\n",
    "        batch_size=args.batch_size, shuffle=False,\n",
    "        num_workers=args.workers, pin_memory=True)\n",
    "\n",
    "    if args.eval_pth != '':\n",
    "        if mox.file.exists(args.eval_pth) and (not mox.file.is_directory(args.eval_pth)):\n",
    "            if args.eval_pth.startswith('s3://'):\n",
    "                model_name = args.eval_pth.rsplit('/', 1)[1]\n",
    "                mox.file.copy(args.eval_pth, '/cache/tmp/' + model_name)\n",
    "                args.eval_pth = '/cache/tmp/' + model_name\n",
    "            print(\"=> loading checkpoint '{}'\".format(args.eval_pth))\n",
    "            if args.gpu is None:\n",
    "                checkpoint = torch.load(args.eval_pth)\n",
    "            else:\n",
    "                # Map model to be loaded to specified single gpu.\n",
    "                loc = 'cuda:{}'.format(args.gpu)\n",
    "                checkpoint = torch.load(args.eval_pth, map_location=loc)\n",
    "            if args.eval_pth.startswith('/cache/tmp/'):\n",
    "                os.remove(args.eval_pth)\n",
    "\n",
    "            args.start_epoch = checkpoint['epoch']\n",
    "            best_acc1 = checkpoint['best_acc1']\n",
    "            if args.gpu is not None:\n",
    "                # best_acc1 may be from a checkpoint from a different GPU\n",
    "                best_acc1 = best_acc1.to(args.gpu)\n",
    "            model.load_state_dict(checkpoint['state_dict'])\n",
    "            optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "            print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                  .format(args.eval_pth, checkpoint['epoch']))\n",
    "        else:\n",
    "            print(\"=> no checkpoint found at '{}'\".format(args.eval_pth))\n",
    "\n",
    "        validate(val_loader, model, criterion, args)\n",
    "        return\n",
    "\n",
    "    for epoch in range(args.start_epoch, args.epochs):\n",
    "        if args.distributed:\n",
    "            train_sampler.set_epoch(epoch)\n",
    "        adjust_learning_rate(optimizer, epoch, args)\n",
    "\n",
    "        # train for one epoch\n",
    "        train(train_loader, model, criterion, optimizer, epoch, args)\n",
    "\n",
    "        # evaluate on validation set\n",
    "        if epoch % args.print_freq == 0:\n",
    "            acc1 = validate(val_loader, model, criterion, args)\n",
    "\n",
    "            # remember best acc@1 and save checkpoint\n",
    "            is_best = False\n",
    "            best_acc1 = max(acc1.item(), best_acc1)\n",
    "            pth_file_name = os.path.join(args.train_local, 'epoch_%s_%s.pth'\n",
    "                                         % (str(epoch), str(round(acc1.item(), 3))))\n",
    "            if not args.multiprocessing_distributed or (args.multiprocessing_distributed\n",
    "                    and args.rank % ngpus_per_node == 0):\n",
    "                save_checkpoint({\n",
    "                    'epoch': epoch,\n",
    "                    'arch': args.arch,\n",
    "                    'state_dict': model.state_dict(),\n",
    "                    'best_acc1': best_acc1,\n",
    "                    'optimizer': optimizer.state_dict(),\n",
    "                }, is_best, pth_file_name, args)\n",
    "\n",
    "    if args.epochs >= args.print_freq:\n",
    "        save_best_checkpoint(best_acc1, args)\n",
    "\n",
    "\n",
    "def train(train_loader, model, criterion, optimizer, epoch, args):\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    data_time = AverageMeter('Data', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(train_loader),\n",
    "        [batch_time, data_time, losses, top1, top5],\n",
    "        prefix=\"Epoch: [{}]\".format(epoch))\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (images, target) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        if args.gpu is not None:\n",
    "            images = images.cuda(args.gpu, non_blocking=True)\n",
    "        target = target.cuda(args.gpu, non_blocking=True)\n",
    "\n",
    "        # compute output\n",
    "        output = model(images)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "        losses.update(loss.item(), images.size(0))\n",
    "        top1.update(acc1[0], images.size(0))\n",
    "        top5.update(acc5[0], images.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % args.print_freq == 0:\n",
    "            progress.display(i)\n",
    "\n",
    "\n",
    "def validate(val_loader, model, criterion, args):\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(val_loader),\n",
    "        [batch_time, losses, top1, top5],\n",
    "        prefix='Test: ')\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for i, (images, target) in enumerate(val_loader):\n",
    "            if args.gpu is not None:\n",
    "                images = images.cuda(args.gpu, non_blocking=True)\n",
    "            target = target.cuda(args.gpu, non_blocking=True)\n",
    "\n",
    "            # compute output\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "            losses.update(loss.item(), images.size(0))\n",
    "            top1.update(acc1[0], images.size(0))\n",
    "            top5.update(acc5[0], images.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % args.print_freq == 0:\n",
    "                progress.display(i)\n",
    "\n",
    "        # TODO: this should also be done with the ProgressMeter\n",
    "        print(' * Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}'\n",
    "              .format(top1=top1, top5=top5))\n",
    "\n",
    "    return top1.avg\n",
    "\n",
    "\n",
    "def save_checkpoint(state, is_best, filename, args):\n",
    "    if not is_best:\n",
    "        torch.save(state, filename)\n",
    "        if args.train_url.startswith('s3'):\n",
    "            mox.file.copy(filename,\n",
    "                          args.train_url + '/' + os.path.basename(filename))\n",
    "            os.remove(filename)\n",
    "\n",
    "\n",
    "def save_best_checkpoint(best_acc1, args):\n",
    "    best_acc1_suffix = '%s.pth' % str(round(best_acc1, 3))\n",
    "    pth_files = mox.file.list_directory(args.train_url)\n",
    "    for pth_name in pth_files:\n",
    "        if pth_name.endswith(best_acc1_suffix):\n",
    "            break\n",
    "\n",
    "    # mox.file可兼容处理本地路径和OBS路径\n",
    "    if not mox.file.exists(os.path.join(args.train_url, 'model')):\n",
    "        mox.file.mk_dir(os.path.join(args.train_url, 'model'))\n",
    "\n",
    "    mox.file.copy(os.path.join(args.train_url, pth_name), os.path.join(args.train_url, 'model/model_best.pth'))\n",
    "    mox.file.copy(os.path.join(args.deploy_script_path, 'config.json'),\n",
    "                  os.path.join(args.train_url, 'model/config.json'))\n",
    "    mox.file.copy(os.path.join(args.deploy_script_path, 'customize_service.py'),\n",
    "                  os.path.join(args.train_url, 'model/customize_service.py'))\n",
    "    if mox.file.exists(os.path.join(args.train_url, 'model/config.json')) and \\\n",
    "            mox.file.exists(os.path.join(args.train_url, 'model/customize_service.py')):\n",
    "        print('copy config.json and customize_service.py success')\n",
    "    else:\n",
    "        print('copy config.json and customize_service.py failed')\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)\n",
    "\n",
    "\n",
    "class ProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch, args):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    lr = args.lr * (0.1 ** (epoch // 30))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inference\n",
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "import codecs\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "# from model_service.pytorch_model_service import PTServingBaseService\n",
    "#\n",
    "# import time\n",
    "# from metric.metrics_manager import MetricsManager\n",
    "# import log\n",
    "# logger = log.getLogger(__name__)\n",
    "\n",
    "\n",
    "class ImageClassificationService():\n",
    "    def __init__(self, model_name, model_path):\n",
    "        self.model_name = model_name\n",
    "        self.model_path = model_path\n",
    "\n",
    "        self.model = models.__dict__['resnet50'](num_classes=54)\n",
    "        self.use_cuda = False\n",
    "        if torch.cuda.is_available():\n",
    "            print('Using GPU for inference')\n",
    "            self.use_cuda = True\n",
    "            checkpoint = torch.load(self.model_path)\n",
    "            self.model = torch.nn.DataParallel(self.model).cuda()\n",
    "            self.model.load_state_dict(checkpoint['state_dict'])\n",
    "        else:\n",
    "            print('Using CPU for inference')\n",
    "            checkpoint = torch.load(self.model_path, map_location='cpu')\n",
    "            state_dict = OrderedDict()\n",
    "            # 训练脚本 main.py 中保存了'epoch', 'arch', 'state_dict', 'best_acc1', 'optimizer'五个key值，\n",
    "            # 其中'state_dict'对应的value才是模型的参数。\n",
    "            # 训练脚本 main.py 中创建模型时用了torch.nn.DataParallel，因此模型保存时的dict都会有‘module.’的前缀，\n",
    "            # 下面 tmp = key[7:] 这行代码的作用就是去掉‘module.’前缀\n",
    "            for key, value in checkpoint['state_dict'].items():\n",
    "                tmp = key[7:]\n",
    "                state_dict[tmp] = value\n",
    "            self.model.load_state_dict(state_dict)\n",
    "\n",
    "        # self.model.eval()\n",
    "\n",
    "        self.normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                         std=[0.229, 0.224, 0.225])\n",
    "\n",
    "        self.transforms = transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            self.normalize\n",
    "        ])\n",
    "\n",
    "        self.label_id_name_dict = \\\n",
    "            {\n",
    "                \"0\": \"工艺品/仿唐三彩\",\n",
    "                \"1\": \"工艺品/仿宋木叶盏\",\n",
    "                \"2\": \"工艺品/布贴绣\",\n",
    "                \"3\": \"工艺品/景泰蓝\",\n",
    "                \"4\": \"工艺品/木马勺脸谱\",\n",
    "                \"5\": \"工艺品/柳编\",\n",
    "                \"6\": \"工艺品/葡萄花鸟纹银香囊\",\n",
    "                \"7\": \"工艺品/西安剪纸\",\n",
    "                \"8\": \"工艺品/陕历博唐妞系列\",\n",
    "                \"9\": \"景点/关中书院\",\n",
    "                \"10\": \"景点/兵马俑\",\n",
    "                \"11\": \"景点/南五台\",\n",
    "                \"12\": \"景点/大兴善寺\",\n",
    "                \"13\": \"景点/大观楼\",\n",
    "                \"14\": \"景点/大雁塔\",\n",
    "                \"15\": \"景点/小雁塔\",\n",
    "                \"16\": \"景点/未央宫城墙遗址\",\n",
    "                \"17\": \"景点/水陆庵壁塑\",\n",
    "                \"18\": \"景点/汉长安城遗址\",\n",
    "                \"19\": \"景点/西安城墙\",\n",
    "                \"20\": \"景点/钟楼\",\n",
    "                \"21\": \"景点/长安华严寺\",\n",
    "                \"22\": \"景点/阿房宫遗址\",\n",
    "                \"23\": \"民俗/唢呐\",\n",
    "                \"24\": \"民俗/皮影\",\n",
    "                \"25\": \"特产/临潼火晶柿子\",\n",
    "                \"26\": \"特产/山茱萸\",\n",
    "                \"27\": \"特产/玉器\",\n",
    "                \"28\": \"特产/阎良甜瓜\",\n",
    "                \"29\": \"特产/陕北红小豆\",\n",
    "                \"30\": \"特产/高陵冬枣\",\n",
    "                \"31\": \"美食/八宝玫瑰镜糕\",\n",
    "                \"32\": \"美食/凉皮\",\n",
    "                \"33\": \"美食/凉鱼\",\n",
    "                \"34\": \"美食/德懋恭水晶饼\",\n",
    "                \"35\": \"美食/搅团\",\n",
    "                \"36\": \"美食/枸杞炖银耳\",\n",
    "                \"37\": \"美食/柿子饼\",\n",
    "                \"38\": \"美食/浆水面\",\n",
    "                \"39\": \"美食/灌汤包\",\n",
    "                \"40\": \"美食/烧肘子\",\n",
    "                \"41\": \"美食/石子饼\",\n",
    "                \"42\": \"美食/神仙粉\",\n",
    "                \"43\": \"美食/粉汤羊血\",\n",
    "                \"44\": \"美食/羊肉泡馍\",\n",
    "                \"45\": \"美食/肉夹馍\",\n",
    "                \"46\": \"美食/荞面饸饹\",\n",
    "                \"47\": \"美食/菠菜面\",\n",
    "                \"48\": \"美食/蜂蜜凉粽子\",\n",
    "                \"49\": \"美食/蜜饯张口酥饺\",\n",
    "                \"50\": \"美食/西安油茶\",\n",
    "                \"51\": \"美食/贵妃鸡翅\",\n",
    "                \"52\": \"美食/醪糟\",\n",
    "                \"53\": \"美食/金线油塔\"\n",
    "            }\n",
    "\n",
    "    def _preprocess(self, data):\n",
    "        preprocessed_data = {}\n",
    "        for k, v in data.items():\n",
    "            for file_name, file_content in v.items():\n",
    "                img = Image.open(file_content)\n",
    "                img = self.transforms(img)\n",
    "                preprocessed_data[k] = img\n",
    "        return preprocessed_data\n",
    "\n",
    "    def _inference(self, data):\n",
    "        img = data[\"input_img\"]\n",
    "        img = img.unsqueeze(0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred_score = self.model(img)\n",
    "            pred_score = F.softmax(pred_score.data, dim=1)\n",
    "            if pred_score is not None:\n",
    "                pred_label = torch.argsort(pred_score[0], descending=True)[:1][0].item()\n",
    "                result = {'result': self.label_id_name_dict[str(pred_label)]}\n",
    "            else:\n",
    "                result = {'result': 'predict score is None'}\n",
    "\n",
    "        return result\n",
    "\n",
    "    def _postprocess(self, data):\n",
    "        return data\n",
    "\n",
    "    # def inference(self, data):\n",
    "    #     \"\"\"\n",
    "    #     Wrapper function to run preprocess, inference and postprocess functions.\n",
    "    #\n",
    "    #     Parameters\n",
    "    #     ----------\n",
    "    #     data : map of object\n",
    "    #         Raw input from request.\n",
    "    #\n",
    "    #     Returns\n",
    "    #     -------\n",
    "    #     list of outputs to be sent back to client.\n",
    "    #         data to be sent back\n",
    "    #     \"\"\"\n",
    "    #     pre_start_time = time.time()\n",
    "    #     data = self._preprocess(data)\n",
    "    #     infer_start_time = time.time()\n",
    "    #\n",
    "    #     # Update preprocess latency metric\n",
    "    #     pre_time_in_ms = (infer_start_time - pre_start_time) * 1000\n",
    "    #     logger.info('preprocess time: ' + str(pre_time_in_ms) + 'ms')\n",
    "    #\n",
    "    #     if self.model_name + '_LatencyPreprocess' in MetricsManager.metrics:\n",
    "    #         MetricsManager.metrics[self.model_name + '_LatencyPreprocess'].update(pre_time_in_ms)\n",
    "    #\n",
    "    #     data = self._inference(data)\n",
    "    #     infer_end_time = time.time()\n",
    "    #     infer_in_ms = (infer_end_time - infer_start_time) * 1000\n",
    "    #\n",
    "    #     logger.info('infer time: ' + str(infer_in_ms) + 'ms')\n",
    "    #     data = self._postprocess(data)\n",
    "    #\n",
    "    #     # Update inference latency metric\n",
    "    #     post_time_in_ms = (time.time() - infer_end_time) * 1000\n",
    "    #     logger.info('postprocess time: ' + str(post_time_in_ms) + 'ms')\n",
    "    #     if self.model_name + '_LatencyInference' in MetricsManager.metrics:\n",
    "    #         MetricsManager.metrics[self.model_name + '_LatencyInference'].update(post_time_in_ms)\n",
    "    #\n",
    "    #     # Update overall latency metric\n",
    "    #     if self.model_name + '_LatencyOverall' in MetricsManager.metrics:\n",
    "    #         MetricsManager.metrics[self.model_name + '_LatencyOverall'].update(pre_time_in_ms + post_time_in_ms)\n",
    "    #\n",
    "    #     logger.info('latency: ' + str(pre_time_in_ms + infer_in_ms + post_time_in_ms) + 'ms')\n",
    "    #     data['latency_time'] = pre_time_in_ms + infer_in_ms + post_time_in_ms\n",
    "    #     time.sleep(1)\n",
    "    #     return data\n",
    "\n",
    "\n",
    "def infer_on_dataset(img_dir, label_dir, model_path):\n",
    "    if not os.path.exists(img_dir):\n",
    "        print('img_dir: %s is not exist' % img_dir)\n",
    "        return None\n",
    "    if not os.path.exists(label_dir):\n",
    "        print('label_dir: %s is not exist' % label_dir)\n",
    "        return None\n",
    "    if not os.path.exists(model_path):\n",
    "        print('model_path: %s is not exist' % model_path)\n",
    "        return None\n",
    "    output_dir = model_path + '_output'\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.mkdir(output_dir)\n",
    "    infer = ImageClassificationService('', model_path)\n",
    "    files = os.listdir(img_dir)\n",
    "    error_results = []\n",
    "    right_count = 0\n",
    "    total_count = 0\n",
    "    for file_name in files:\n",
    "        if not file_name.endswith('jpg'):\n",
    "            continue\n",
    "\n",
    "        with codecs.open(os.path.join(label_dir, file_name.split('.jpg')[0] + '.txt'), 'r', 'utf-8') as f:\n",
    "            line = f.readline()\n",
    "        line_split = line.strip().split(', ')\n",
    "        if len(line_split) != 2:\n",
    "            print('%s contain error lable' % os.path.basename(file_name.split('.jpg')[0] + '.txt'))\n",
    "            continue\n",
    "        gt_label = infer.label_id_name_dict[line_split[1]]\n",
    "        # gt_label = \"工艺品/仿唐三彩\"\n",
    "\n",
    "        img_path = os.path.join(img_dir, file_name)\n",
    "        img = Image.open(img_path)\n",
    "        img = infer.transforms(img)\n",
    "        result = infer._inference({\"input_img\": img})\n",
    "        pred_label = result.get('result', 'error')\n",
    "\n",
    "        total_count += 1\n",
    "        if pred_label == gt_label:\n",
    "            right_count += 1\n",
    "        else:\n",
    "            error_results.append(', '.join([file_name, gt_label, pred_label]) + '\\n')\n",
    "\n",
    "    acc = float(right_count) / total_count\n",
    "    result_file_path = os.path.join(output_dir, 'accuracy.txt')\n",
    "    with codecs.open(result_file_path, 'w', 'utf-8') as f:\n",
    "        f.write('# predict error files\\n')\n",
    "        f.write('####################################\\n')\n",
    "        f.write('file_name, gt_label, pred_label\\n')\n",
    "        f.writelines(error_results)\n",
    "        f.write('####################################\\n')\n",
    "        f.write('accuracy: %s\\n' % acc)\n",
    "    print('accuracy result file saved as %s' % result_file_path)\n",
    "    print('accuracy: %0.4f' % acc)\n",
    "    return acc, result_file_path\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    img_dir = r'/home/ma-user/work/xi_an_ai/datasets/test_data'\n",
    "    label_dir = r'/home/ma-user/work/xi_an_ai/datasets/test_data'\n",
    "    model_path = r'/home/ma-user/work/xi_an_ai/model_snapshots/pytorch/V0001/model/model_best.pth'\n",
    "    infer_on_dataset(img_dir, label_dir, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-22T11:18:22.238Z"
    },
    "code_folding": [
     35
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第1已完成\n",
      "第2已完成\n",
      "第3已完成\n",
      "第4已完成\n",
      "第5已完成\n",
      "第6已完成\n",
      "第7已完成\n",
      "第8已完成\n",
      "第9已完成\n",
      "第10已完成\n",
      "第11已完成\n",
      "第12已完成\n",
      "第13已完成\n",
      "第14已完成\n",
      "第15已完成\n",
      "第16已完成\n",
      "第17已完成\n",
      "第18已完成\n",
      "第19已完成\n",
      "第20已完成\n",
      "第21已完成\n",
      "第22已完成\n",
      "第23已完成\n",
      "第24已完成\n",
      "第25已完成\n",
      "第26已完成\n",
      "第27已完成\n",
      "第28已完成\n",
      "第29已完成\n",
      "第30已完成\n",
      "第31已完成\n",
      "第32已完成\n",
      "第33已完成\n",
      "第34已完成\n",
      "第35已完成\n",
      "第36已完成\n",
      "第37已完成\n",
      "第38已完成\n",
      "第39已完成\n",
      "第40已完成\n",
      "第41已完成\n",
      "第42已完成\n",
      "第43已完成\n",
      "第44已完成\n",
      "第45已完成\n",
      "第46已完成\n",
      "第47已完成\n",
      "第48已完成\n",
      "第49已完成\n",
      "第50已完成\n",
      "第51已完成\n",
      "第52已完成\n",
      "第53已完成\n",
      "第54已完成\n",
      "第55已完成\n",
      "第56已完成\n",
      "第57已完成\n",
      "第58已完成\n",
      "第59已完成\n",
      "第60已完成\n",
      "第61已完成\n",
      "第62已完成\n",
      "第63已完成\n",
      "第64已完成\n",
      "第65已完成\n",
      "第66已完成\n",
      "第67已完成\n",
      "第68已完成\n",
      "第69已完成\n",
      "第70已完成\n",
      "第71已完成\n",
      "第72已完成\n",
      "第73已完成\n",
      "第74已完成\n",
      "第75已完成\n",
      "第76已完成\n",
      "第77已完成\n",
      "第78已完成\n",
      "第79已完成\n",
      "第80已完成\n",
      "第81已完成\n",
      "第82已完成\n",
      "第83已完成\n",
      "第84已完成\n",
      "第85已完成\n",
      "第86已完成\n",
      "第87已完成\n",
      "第88已完成\n",
      "第89已完成\n",
      "第90已完成\n",
      "第91已完成\n",
      "第92已完成\n",
      "第93已完成\n",
      "第94已完成\n",
      "第95已完成\n",
      "第96已完成\n",
      "第97已完成\n",
      "第98已完成\n",
      "第99已完成\n",
      "第100已完成\n",
      "第101已完成\n",
      "第102已完成\n",
      "第103已完成\n",
      "第104已完成\n",
      "第105已完成\n",
      "第106已完成\n",
      "第107已完成\n",
      "第108已完成\n",
      "第109已完成\n",
      "第110已完成\n",
      "第111已完成\n",
      "第112已完成\n",
      "第113已完成\n",
      "第114已完成\n",
      "第115已完成\n",
      "第116已完成\n",
      "第117已完成\n",
      "第118已完成\n",
      "第119已完成\n",
      "第120已完成\n",
      "第121已完成\n",
      "第122已完成\n",
      "第123已完成\n",
      "第124已完成\n",
      "第125已完成\n",
      "第126已完成\n",
      "第127已完成\n",
      "第128已完成\n",
      "第129已完成\n",
      "第130已完成\n",
      "第131已完成\n",
      "第132已完成\n",
      "第133已完成\n",
      "第134已完成\n",
      "第135已完成\n",
      "第136已完成\n",
      "第137已完成\n",
      "第138已完成\n",
      "第139已完成\n",
      "第140已完成\n",
      "第141已完成\n",
      "第142已完成\n",
      "第143已完成\n",
      "第144已完成\n",
      "第145已完成\n",
      "第146已完成\n",
      "第147已完成\n",
      "第148已完成\n",
      "第149已完成\n",
      "第150已完成\n",
      "第151已完成\n",
      "第152已完成\n",
      "第153已完成\n",
      "第154已完成\n",
      "第155已完成\n",
      "第156已完成\n",
      "第157已完成\n",
      "第158已完成\n",
      "第159已完成\n",
      "第160已完成\n",
      "第161已完成\n",
      "第162已完成\n",
      "第163已完成\n",
      "第164已完成\n",
      "第165已完成\n",
      "第166已完成\n",
      "第167已完成\n",
      "第168已完成\n",
      "第169已完成\n",
      "第170已完成\n",
      "第171已完成\n",
      "第172已完成\n",
      "第173已完成\n",
      "第174已完成\n",
      "第175已完成\n",
      "第176已完成\n",
      "第177已完成\n",
      "第178已完成\n",
      "第179已完成\n",
      "第180已完成\n",
      "第181已完成\n",
      "第182已完成\n",
      "第183已完成\n",
      "第184已完成\n",
      "第185已完成\n",
      "第186已完成\n",
      "第187已完成\n",
      "第188已完成\n",
      "第189已完成\n",
      "第190已完成\n",
      "第191已完成\n",
      "第192已完成\n",
      "第193已完成\n",
      "第194已完成\n",
      "第195已完成\n",
      "第196已完成\n",
      "第197已完成\n",
      "第198已完成\n",
      "第199已完成\n",
      "第200已完成\n",
      "第201已完成\n",
      "第202已完成\n",
      "第203已完成\n",
      "第204已完成\n",
      "第205已完成\n",
      "第206已完成\n",
      "第207已完成\n",
      "第208已完成\n",
      "第209已完成\n",
      "第210已完成\n",
      "第211已完成\n",
      "第212已完成\n",
      "第213已完成\n",
      "第214已完成\n",
      "第215已完成\n",
      "第216已完成\n",
      "第217已完成\n",
      "第218已完成\n",
      "第219已完成\n",
      "第220已完成\n",
      "第221已完成\n",
      "第222已完成\n",
      "第223已完成\n",
      "第224已完成\n",
      "第225已完成\n",
      "第226已完成\n",
      "第227已完成\n",
      "第228已完成\n",
      "第229已完成\n",
      "第230已完成\n",
      "第231已完成\n",
      "第232已完成\n",
      "第233已完成\n",
      "第234已完成\n",
      "第235已完成\n",
      "第236已完成\n",
      "第237已完成\n",
      "第238已完成\n",
      "第239已完成\n",
      "第240已完成\n",
      "第241已完成\n",
      "第242已完成\n",
      "第243已完成\n",
      "第244已完成\n",
      "第245已完成\n",
      "第246已完成\n",
      "第247已完成\n",
      "第248已完成\n",
      "第249已完成\n",
      "第250已完成\n",
      "第251已完成\n",
      "第252已完成\n",
      "第253已完成\n",
      "第254已完成\n",
      "第255已完成\n",
      "第256已完成\n",
      "第257已完成\n",
      "第258已完成\n",
      "第259已完成\n",
      "第260已完成\n",
      "第261已完成\n",
      "第262已完成\n",
      "第263已完成\n",
      "第264已完成\n",
      "第265已完成\n",
      "第266已完成\n",
      "第267已完成\n",
      "第268已完成\n",
      "第269已完成\n",
      "第270已完成\n",
      "第271已完成\n",
      "第272已完成\n",
      "第273已完成\n",
      "第274已完成\n",
      "第275已完成\n",
      "第276已完成\n",
      "第277已完成\n",
      "第278已完成\n",
      "第279已完成\n",
      "第280已完成\n",
      "第281已完成\n",
      "第282已完成\n",
      "第283已完成\n",
      "第284已完成\n",
      "第285已完成\n",
      "第286已完成\n",
      "第287已完成\n",
      "第288已完成\n",
      "第289已完成\n",
      "第290已完成\n",
      "第291已完成\n",
      "第292已完成\n",
      "第293已完成\n",
      "第294已完成\n",
      "第295已完成\n",
      "第296已完成\n",
      "第297已完成\n",
      "第298已完成\n",
      "第299已完成\n",
      "第300已完成\n",
      "第301已完成\n",
      "第302已完成\n",
      "第303已完成\n",
      "第304已完成\n",
      "第305已完成\n",
      "第306已完成\n",
      "第307已完成\n",
      "第308已完成\n",
      "第309已完成\n",
      "第310已完成\n",
      "第311已完成\n",
      "第312已完成\n",
      "第313已完成\n",
      "第314已完成\n",
      "第315已完成\n",
      "第316已完成\n",
      "第317已完成\n",
      "第318已完成\n",
      "第319已完成\n",
      "第320已完成\n",
      "第321已完成\n",
      "第322已完成\n",
      "第323已完成\n",
      "第324已完成\n",
      "第325已完成\n",
      "第326已完成\n",
      "第327已完成\n",
      "第328已完成\n",
      "第329已完成\n",
      "第330已完成\n",
      "第331已完成\n",
      "第332已完成\n",
      "第333已完成\n",
      "第334已完成\n",
      "第335已完成\n",
      "第336已完成\n",
      "第337已完成\n",
      "第338已完成\n",
      "第339已完成\n",
      "第340已完成\n",
      "第341已完成\n",
      "第342已完成\n",
      "第343已完成\n",
      "第344已完成\n",
      "第345已完成\n",
      "第346已完成\n",
      "第347已完成\n",
      "第348已完成\n",
      "第349已完成\n",
      "第350已完成\n",
      "第351已完成\n",
      "第352已完成\n",
      "第353已完成\n",
      "第354已完成\n",
      "第355已完成\n",
      "第356已完成\n",
      "第357已完成\n",
      "第358已完成\n",
      "第359已完成\n",
      "第360已完成\n",
      "第361已完成\n",
      "第362已完成\n",
      "第363已完成\n",
      "第364已完成\n",
      "第365已完成\n",
      "第366已完成\n",
      "第367已完成\n",
      "第368已完成\n",
      "第369已完成\n",
      "第370已完成\n",
      "第371已完成\n",
      "第372已完成\n",
      "第373已完成\n",
      "第374已完成\n",
      "第375已完成\n",
      "第376已完成\n",
      "第377已完成\n",
      "第378已完成\n",
      "第379已完成\n",
      "第380已完成\n",
      "第381已完成\n",
      "第382已完成\n",
      "第383已完成\n",
      "第384已完成\n",
      "第385已完成\n",
      "第386已完成\n",
      "第387已完成\n",
      "第388已完成\n",
      "第389已完成\n",
      "第390已完成\n",
      "第391已完成\n",
      "第392已完成\n",
      "第393已完成\n",
      "第394已完成\n",
      "第395已完成\n",
      "第396已完成\n",
      "第397已完成\n",
      "第398已完成\n",
      "第399已完成\n",
      "第400已完成\n",
      "第401已完成\n",
      "第402已完成\n",
      "第403已完成\n",
      "第404已完成\n",
      "第405已完成\n",
      "第406已完成\n",
      "第407已完成\n",
      "第408已完成\n",
      "第409已完成\n",
      "第410已完成\n",
      "第411已完成\n",
      "第412已完成\n",
      "第413已完成\n",
      "第414已完成\n",
      "第415已完成\n",
      "第416已完成\n",
      "第417已完成\n",
      "第418已完成\n",
      "第419已完成\n",
      "第420已完成\n",
      "第421已完成\n",
      "第422已完成\n",
      "第423已完成\n",
      "第424已完成\n",
      "第425已完成\n",
      "第426已完成\n",
      "第427已完成\n",
      "第428已完成\n",
      "第429已完成\n",
      "第430已完成\n",
      "第431已完成\n",
      "第432已完成\n",
      "第433已完成\n",
      "第434已完成\n",
      "第435已完成\n",
      "第436已完成\n",
      "第437已完成\n",
      "第438已完成\n",
      "第439已完成\n",
      "第440已完成\n",
      "第441已完成\n",
      "第442已完成\n",
      "第443已完成\n",
      "第444已完成\n",
      "第445已完成\n",
      "第446已完成\n",
      "第447已完成\n",
      "第448已完成\n",
      "第449已完成\n",
      "第450已完成\n",
      "第451已完成\n",
      "第452已完成\n",
      "第453已完成\n",
      "第454已完成\n",
      "第455已完成\n",
      "第456已完成\n",
      "第457已完成\n",
      "第458已完成\n",
      "第459已完成\n",
      "第460已完成\n",
      "第461已完成\n",
      "第462已完成\n",
      "第463已完成\n",
      "第464已完成\n",
      "第465已完成\n",
      "第466已完成\n",
      "第467已完成\n",
      "第468已完成\n",
      "第469已完成\n",
      "第470已完成\n",
      "第471已完成\n",
      "第472已完成\n",
      "第473已完成\n",
      "第474已完成\n",
      "第475已完成\n",
      "第476已完成\n",
      "第477已完成\n",
      "第478已完成\n",
      "第479已完成\n",
      "第480已完成\n",
      "第481已完成\n",
      "第482已完成\n",
      "第483已完成\n",
      "第484已完成\n",
      "第485已完成\n",
      "第486已完成\n",
      "第487已完成\n",
      "第488已完成\n",
      "第489已完成\n",
      "第490已完成\n",
      "第491已完成\n",
      "第492已完成\n",
      "第493已完成\n",
      "第494已完成\n",
      "第495已完成\n",
      "第496已完成\n",
      "第497已完成\n",
      "第498已完成\n",
      "第499已完成\n",
      "第500已完成\n",
      "第501已完成\n",
      "第502已完成\n",
      "第503已完成\n",
      "第504已完成\n",
      "第505已完成\n",
      "第506已完成\n",
      "第507已完成\n",
      "第508已完成\n",
      "第509已完成\n",
      "第510已完成\n",
      "第511已完成\n",
      "第512已完成\n",
      "第513已完成\n",
      "第514已完成\n",
      "第515已完成\n",
      "第516已完成\n",
      "第517已完成\n",
      "第518已完成\n",
      "第519已完成\n",
      "第520已完成\n",
      "第521已完成\n",
      "第522已完成\n",
      "第523已完成\n",
      "第524已完成\n",
      "第525已完成\n",
      "第526已完成\n",
      "第527已完成\n",
      "第528已完成\n",
      "第529已完成\n",
      "第530已完成\n",
      "第531已完成\n",
      "第532已完成\n",
      "第533已完成\n",
      "第534已完成\n",
      "第535已完成\n",
      "第536已完成\n",
      "第537已完成\n",
      "第538已完成\n",
      "第539已完成\n",
      "第540已完成\n",
      "第541已完成\n",
      "第542已完成\n",
      "第543已完成\n",
      "第544已完成\n",
      "第545已完成\n",
      "第546已完成\n",
      "第547已完成\n",
      "第548已完成\n",
      "第549已完成\n",
      "第550已完成\n",
      "第551已完成\n",
      "第552已完成\n",
      "第553已完成\n",
      "第554已完成\n",
      "第555已完成\n",
      "第556已完成\n",
      "第557已完成\n",
      "第558已完成\n",
      "第559已完成\n",
      "第560已完成\n",
      "第561已完成\n",
      "第562已完成\n",
      "第563已完成\n",
      "第564已完成\n",
      "第565已完成\n",
      "第566已完成\n",
      "第567已完成\n",
      "第568已完成\n",
      "第569已完成\n",
      "第570已完成\n",
      "第571已完成\n",
      "第572已完成\n",
      "第573已完成\n",
      "第574已完成\n",
      "第575已完成\n",
      "第576已完成\n",
      "第577已完成\n",
      "第578已完成\n",
      "第579已完成\n",
      "第580已完成\n",
      "第581已完成\n",
      "第582已完成\n",
      "第583已完成\n",
      "第584已完成\n",
      "第585已完成\n",
      "第586已完成\n",
      "第587已完成\n",
      "第588已完成\n",
      "第589已完成\n",
      "第590已完成\n",
      "第591已完成\n",
      "第592已完成\n",
      "第593已完成\n",
      "第594已完成\n",
      "第595已完成\n",
      "第596已完成\n",
      "第597已完成\n",
      "第598已完成\n",
      "第599已完成\n",
      "第600已完成\n",
      "第601已完成\n",
      "第602已完成\n",
      "第603已完成\n",
      "第604已完成\n",
      "第605已完成\n",
      "第606已完成\n",
      "第607已完成\n",
      "第608已完成\n",
      "第609已完成\n",
      "第610已完成\n",
      "第611已完成\n",
      "第612已完成\n",
      "第613已完成\n",
      "第614已完成\n",
      "第615已完成\n",
      "第616已完成\n",
      "第617已完成\n",
      "第618已完成\n",
      "第619已完成\n",
      "第620已完成\n",
      "第621已完成\n",
      "第622已完成\n",
      "第623已完成\n",
      "第624已完成\n",
      "第625已完成\n",
      "第626已完成\n",
      "第627已完成\n",
      "第628已完成\n",
      "第629已完成\n",
      "第630已完成\n",
      "第631已完成\n",
      "第632已完成\n",
      "第633已完成\n",
      "第634已完成\n",
      "第635已完成\n",
      "第636已完成\n",
      "第637已完成\n",
      "第638已完成\n",
      "第639已完成\n",
      "第640已完成\n",
      "第641已完成\n",
      "第642已完成\n",
      "第643已完成\n",
      "第644已完成\n",
      "第645已完成\n",
      "第646已完成\n",
      "第647已完成\n",
      "第648已完成\n",
      "第649已完成\n",
      "第650已完成\n",
      "第651已完成\n",
      "第652已完成\n",
      "第653已完成\n",
      "第654已完成\n",
      "第655已完成\n",
      "第656已完成\n",
      "第657已完成\n",
      "第658已完成\n",
      "第659已完成\n",
      "第660已完成\n",
      "第661已完成\n",
      "第662已完成\n",
      "第663已完成\n",
      "第664已完成\n",
      "第665已完成\n",
      "第666已完成\n",
      "第667已完成\n",
      "第668已完成\n",
      "第669已完成\n",
      "第670已完成\n",
      "第671已完成\n",
      "第672已完成\n",
      "第673已完成\n",
      "第674已完成\n",
      "第675已完成\n",
      "第676已完成\n",
      "第677已完成\n",
      "第678已完成\n",
      "第679已完成\n",
      "第680已完成\n",
      "第681已完成\n",
      "第682已完成\n",
      "第683已完成\n",
      "第684已完成\n",
      "第685已完成\n",
      "第686已完成\n",
      "第687已完成\n",
      "第688已完成\n",
      "第689已完成\n",
      "第690已完成\n",
      "第691已完成\n",
      "第692已完成\n",
      "第693已完成\n",
      "第694已完成\n",
      "第695已完成\n",
      "第696已完成\n",
      "第697已完成\n",
      "第698已完成\n",
      "第699已完成\n",
      "第700已完成\n",
      "第701已完成\n",
      "第702已完成\n",
      "第703已完成\n",
      "第704已完成\n",
      "第705已完成\n",
      "第706已完成\n",
      "第707已完成\n",
      "第708已完成\n",
      "第709已完成\n",
      "第710已完成\n",
      "第711已完成\n",
      "第712已完成\n",
      "第713已完成\n",
      "第714已完成\n",
      "第715已完成\n",
      "第716已完成\n",
      "第717已完成\n",
      "第718已完成\n",
      "第719已完成\n",
      "第720已完成\n",
      "第721已完成\n",
      "第722已完成\n",
      "第723已完成\n",
      "第724已完成\n",
      "第725已完成\n",
      "第726已完成\n",
      "第727已完成\n",
      "第728已完成\n",
      "第729已完成\n",
      "第730已完成\n",
      "第731已完成\n",
      "第732已完成\n",
      "第733已完成\n",
      "第734已完成\n",
      "第735已完成\n",
      "第736已完成\n",
      "第737已完成\n",
      "第738已完成\n",
      "第739已完成\n",
      "第740已完成\n",
      "第741已完成\n",
      "第742已完成\n",
      "第743已完成\n",
      "第744已完成\n",
      "第745已完成\n",
      "第746已完成\n",
      "第747已完成\n",
      "第748已完成\n",
      "第749已完成\n",
      "第750已完成\n",
      "第751已完成\n",
      "第752已完成\n",
      "第753已完成\n",
      "第754已完成\n",
      "第755已完成\n",
      "第756已完成\n",
      "第757已完成\n",
      "第758已完成\n",
      "第759已完成\n",
      "第760已完成\n",
      "第761已完成\n",
      "第762已完成\n",
      "第763已完成\n",
      "第764已完成\n",
      "第765已完成\n",
      "第766已完成\n",
      "第767已完成\n",
      "第768已完成\n",
      "第769已完成\n",
      "第770已完成\n",
      "第771已完成\n",
      "第772已完成\n",
      "第773已完成\n",
      "第774已完成\n",
      "第775已完成\n",
      "第776已完成\n",
      "第777已完成\n",
      "第778已完成\n",
      "第779已完成\n",
      "第780已完成\n",
      "第781已完成\n",
      "第782已完成\n",
      "第783已完成\n",
      "第784已完成\n",
      "第785已完成\n",
      "第786已完成\n",
      "第787已完成\n",
      "第788已完成\n",
      "第789已完成\n",
      "第790已完成\n",
      "第791已完成\n",
      "第792已完成\n",
      "第793已完成\n",
      "第794已完成\n",
      "第795已完成\n",
      "第796已完成\n",
      "第797已完成\n",
      "第798已完成\n",
      "第799已完成\n",
      "第800已完成\n",
      "第801已完成\n",
      "第802已完成\n",
      "第803已完成\n",
      "第804已完成\n",
      "第805已完成\n",
      "第806已完成\n",
      "第807已完成\n",
      "第808已完成\n",
      "第809已完成\n",
      "第810已完成\n",
      "第811已完成\n",
      "第812已完成\n",
      "第813已完成\n",
      "第814已完成\n",
      "第815已完成\n",
      "第816已完成\n",
      "第817已完成\n",
      "第818已完成\n",
      "第819已完成\n",
      "第820已完成\n",
      "第821已完成\n",
      "第822已完成\n",
      "第823已完成\n",
      "第824已完成\n",
      "第825已完成\n",
      "第826已完成\n",
      "第827已完成\n",
      "第828已完成\n",
      "第829已完成\n",
      "第830已完成\n",
      "第831已完成\n",
      "第832已完成\n",
      "第833已完成\n",
      "第834已完成\n",
      "第835已完成\n",
      "第836已完成\n",
      "第837已完成\n",
      "第838已完成\n",
      "第839已完成\n",
      "第840已完成\n",
      "第841已完成\n",
      "第842已完成\n",
      "第843已完成\n",
      "第844已完成\n",
      "第845已完成\n",
      "第846已完成\n",
      "第847已完成\n",
      "第848已完成\n",
      "第849已完成\n",
      "第850已完成\n",
      "第851已完成\n",
      "第852已完成\n",
      "第853已完成\n",
      "第854已完成\n",
      "第855已完成\n",
      "第856已完成\n",
      "第857已完成\n",
      "第858已完成\n",
      "第859已完成\n",
      "第860已完成\n",
      "第861已完成\n",
      "第862已完成\n",
      "第863已完成\n",
      "第864已完成\n",
      "第865已完成\n",
      "第866已完成\n",
      "第867已完成\n",
      "第868已完成\n",
      "第869已完成\n",
      "第870已完成\n",
      "第871已完成\n",
      "第872已完成\n",
      "第873已完成\n",
      "第874已完成\n",
      "第875已完成\n",
      "第876已完成\n",
      "第877已完成\n",
      "第878已完成\n",
      "第879已完成\n",
      "第880已完成\n",
      "第881已完成\n",
      "第882已完成\n",
      "第883已完成\n",
      "第884已完成\n",
      "第885已完成\n",
      "第886已完成\n",
      "第887已完成\n",
      "第888已完成\n",
      "第889已完成\n",
      "第890已完成\n",
      "第891已完成\n",
      "第892已完成\n",
      "第893已完成\n",
      "第894已完成\n",
      "第895已完成\n",
      "第896已完成\n",
      "第897已完成\n",
      "第898已完成\n",
      "第899已完成\n",
      "第900已完成\n",
      "第901已完成\n",
      "第902已完成\n",
      "第903已完成\n",
      "第904已完成\n",
      "第905已完成\n",
      "第906已完成\n",
      "第907已完成\n",
      "第908已完成\n",
      "第909已完成\n",
      "第910已完成\n",
      "第911已完成\n",
      "第912已完成\n",
      "第913已完成\n",
      "第914已完成\n",
      "第915已完成\n",
      "第916已完成\n",
      "第917已完成\n",
      "第918已完成\n",
      "第919已完成\n",
      "第920已完成\n",
      "第921已完成\n",
      "第922已完成\n",
      "第923已完成\n",
      "第924已完成\n",
      "第925已完成\n",
      "第926已完成\n",
      "第927已完成\n",
      "第928已完成\n",
      "第929已完成\n",
      "第930已完成\n",
      "第931已完成\n",
      "第932已完成\n",
      "第933已完成\n",
      "第934已完成\n",
      "第935已完成\n",
      "第936已完成\n",
      "第937已完成\n",
      "第938已完成\n",
      "第939已完成\n",
      "第940已完成\n",
      "第941已完成\n",
      "第942已完成\n",
      "第943已完成\n",
      "第944已完成\n",
      "第945已完成\n",
      "第946已完成\n",
      "第947已完成\n",
      "第948已完成\n",
      "第949已完成\n",
      "第950已完成\n",
      "第951已完成\n",
      "第952已完成\n",
      "第953已完成\n",
      "第954已完成\n",
      "第955已完成\n",
      "第956已完成\n",
      "第957已完成\n",
      "第958已完成\n",
      "第959已完成\n",
      "第960已完成\n",
      "第961已完成\n",
      "第962已完成\n",
      "第963已完成\n",
      "第964已完成\n",
      "第965已完成\n",
      "第966已完成\n",
      "第967已完成\n",
      "第968已完成\n",
      "第969已完成\n",
      "第970已完成\n",
      "第971已完成\n",
      "第972已完成\n",
      "第973已完成\n",
      "第974已完成\n",
      "第975已完成\n",
      "第976已完成\n",
      "第977已完成\n",
      "第978已完成\n",
      "第979已完成\n",
      "第980已完成\n",
      "第981已完成\n",
      "第982已完成\n",
      "第983已完成\n",
      "第984已完成\n",
      "第985已完成\n",
      "第986已完成\n",
      "第987已完成\n",
      "第988已完成\n",
      "第989已完成\n",
      "第990已完成\n",
      "第991已完成\n",
      "第992已完成\n",
      "第993已完成\n",
      "第994已完成\n",
      "第995已完成\n",
      "第996已完成\n",
      "第997已完成\n",
      "第998已完成\n",
      "第999已完成\n",
      "第1000已完成\n",
      "第1001已完成\n",
      "第1002已完成\n",
      "第1003已完成\n",
      "第1004已完成\n",
      "第1005已完成\n",
      "第1006已完成\n",
      "第1007已完成\n",
      "第1008已完成\n",
      "第1009已完成\n",
      "第1010已完成\n",
      "第1011已完成\n",
      "第1012已完成\n",
      "第1013已完成\n",
      "第1014已完成\n",
      "第1015已完成\n",
      "第1016已完成\n",
      "第1017已完成\n",
      "第1018已完成\n",
      "第1019已完成\n",
      "第1020已完成\n",
      "第1021已完成\n",
      "第1022已完成\n",
      "第1023已完成\n",
      "第1024已完成\n",
      "第1025已完成\n",
      "第1026已完成\n",
      "第1027已完成\n",
      "第1028已完成\n",
      "第1029已完成\n",
      "第1030已完成\n",
      "第1031已完成\n",
      "第1032已完成\n",
      "第1033已完成\n",
      "第1034已完成\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第1035已完成\n",
      "第1036已完成\n",
      "第1037已完成\n",
      "第1038已完成\n",
      "第1039已完成\n",
      "第1040已完成\n",
      "第1041已完成\n",
      "第1042已完成\n",
      "第1043已完成\n",
      "第1044已完成\n",
      "第1045已完成\n",
      "第1046已完成\n",
      "第1047已完成\n",
      "第1048已完成\n",
      "第1049已完成\n",
      "第1050已完成\n",
      "第1051已完成\n",
      "第1052已完成\n",
      "第1053已完成\n",
      "第1054已完成\n",
      "第1055已完成\n",
      "第1056已完成\n",
      "第1057已完成\n",
      "第1058已完成\n",
      "第1059已完成\n",
      "第1060已完成\n",
      "第1061已完成\n",
      "第1062已完成\n",
      "第1063已完成\n",
      "第1064已完成\n",
      "第1065已完成\n",
      "第1066已完成\n",
      "第1067已完成\n",
      "第1068已完成\n",
      "第1069已完成\n",
      "第1070已完成\n",
      "第1071已完成\n",
      "第1072已完成\n",
      "第1073已完成\n",
      "第1074已完成\n",
      "第1075已完成\n",
      "第1076已完成\n",
      "第1077已完成\n",
      "第1078已完成\n",
      "第1079已完成\n",
      "第1080已完成\n",
      "第1081已完成\n",
      "第1082已完成\n",
      "第1083已完成\n",
      "第1084已完成\n",
      "第1085已完成\n",
      "第1086已完成\n",
      "第1087已完成\n",
      "第1088已完成\n",
      "第1089已完成\n",
      "第1090已完成\n",
      "第1091已完成\n",
      "第1092已完成\n",
      "第1093已完成\n",
      "第1094已完成\n",
      "第1095已完成\n",
      "第1096已完成\n",
      "第1097已完成\n",
      "第1098已完成\n",
      "第1099已完成\n",
      "第1100已完成\n",
      "第1101已完成\n",
      "第1102已完成\n",
      "第1103已完成\n",
      "第1104已完成\n",
      "第1105已完成\n",
      "第1106已完成\n",
      "第1107已完成\n",
      "第1108已完成\n",
      "第1109已完成\n",
      "第1110已完成\n",
      "第1111已完成\n",
      "第1112已完成\n",
      "第1113已完成\n",
      "第1114已完成\n",
      "第1115已完成\n",
      "第1116已完成\n",
      "第1117已完成\n",
      "第1118已完成\n",
      "第1119已完成\n",
      "第1120已完成\n",
      "第1121已完成\n",
      "第1122已完成\n",
      "第1123已完成\n",
      "第1124已完成\n",
      "第1125已完成\n",
      "第1126已完成\n",
      "第1127已完成\n",
      "第1128已完成\n",
      "第1129已完成\n",
      "第1130已完成\n",
      "第1131已完成\n",
      "第1132已完成\n",
      "第1133已完成\n",
      "第1134已完成\n",
      "第1135已完成\n",
      "第1136已完成\n",
      "第1137已完成\n",
      "第1138已完成\n",
      "第1139已完成\n",
      "第1140已完成\n",
      "第1141已完成\n",
      "第1142已完成\n",
      "第1143已完成\n",
      "第1144已完成\n",
      "第1145已完成\n",
      "第1146已完成\n",
      "第1147已完成\n",
      "第1148已完成\n",
      "第1149已完成\n",
      "第1150已完成\n",
      "第1151已完成\n",
      "第1152已完成\n",
      "第1153已完成\n",
      "第1154已完成\n",
      "第1155已完成\n",
      "第1156已完成\n",
      "第1157已完成\n",
      "第1158已完成\n",
      "第1159已完成\n",
      "第1160已完成\n",
      "第1161已完成\n",
      "第1162已完成\n",
      "第1163已完成\n",
      "第1164已完成\n",
      "第1165已完成\n",
      "第1166已完成\n",
      "第1167已完成\n",
      "第1168已完成\n",
      "第1169已完成\n",
      "第1170已完成\n",
      "第1171已完成\n",
      "第1172已完成\n",
      "第1173已完成\n",
      "第1174已完成\n",
      "第1175已完成\n",
      "第1176已完成\n",
      "第1177已完成\n",
      "第1178已完成\n",
      "第1179已完成\n",
      "第1180已完成\n",
      "第1181已完成\n",
      "第1182已完成\n",
      "第1183已完成\n",
      "第1184已完成\n",
      "第1185已完成\n",
      "第1186已完成\n",
      "第1187已完成\n",
      "第1188已完成\n",
      "第1189已完成\n",
      "第1190已完成\n",
      "第1191已完成\n",
      "第1192已完成\n",
      "第1193已完成\n",
      "第1194已完成\n",
      "第1195已完成\n",
      "第1196已完成\n",
      "第1197已完成\n",
      "第1198已完成\n",
      "第1199已完成\n",
      "第1200已完成\n",
      "第1201已完成\n",
      "第1202已完成\n",
      "第1203已完成\n",
      "第1204已完成\n",
      "第1205已完成\n",
      "第1206已完成\n",
      "第1207已完成\n",
      "第1208已完成\n",
      "第1209已完成\n",
      "第1210已完成\n",
      "第1211已完成\n",
      "第1212已完成\n",
      "第1213已完成\n",
      "第1214已完成\n",
      "第1215已完成\n",
      "第1216已完成\n",
      "第1217已完成\n",
      "第1218已完成\n",
      "第1219已完成\n",
      "第1220已完成\n",
      "第1221已完成\n",
      "第1222已完成\n",
      "第1223已完成\n",
      "第1224已完成\n",
      "第1225已完成\n",
      "第1226已完成\n",
      "第1227已完成\n",
      "第1228已完成\n",
      "第1229已完成\n",
      "第1230已完成\n",
      "第1231已完成\n",
      "第1232已完成\n",
      "第1233已完成\n",
      "第1234已完成\n",
      "第1235已完成\n",
      "第1236已完成\n",
      "第1237已完成\n",
      "第1238已完成\n",
      "第1239已完成\n",
      "第1240已完成\n",
      "第1241已完成\n",
      "第1242已完成\n",
      "第1243已完成\n",
      "第1244已完成\n",
      "第1245已完成\n",
      "第1246已完成\n",
      "第1247已完成\n",
      "第1248已完成\n",
      "第1249已完成\n",
      "第1250已完成\n",
      "第1251已完成\n",
      "第1252已完成\n",
      "第1253已完成\n",
      "第1254已完成\n",
      "第1255已完成\n",
      "第1256已完成\n",
      "第1257已完成\n",
      "第1258已完成\n",
      "第1259已完成\n",
      "第1260已完成\n",
      "第1261已完成\n",
      "第1262已完成\n",
      "第1263已完成\n",
      "第1264已完成\n",
      "第1265已完成\n",
      "第1266已完成\n",
      "第1267已完成\n",
      "第1268已完成\n",
      "第1269已完成\n",
      "第1270已完成\n",
      "第1271已完成\n",
      "第1272已完成\n",
      "第1273已完成\n",
      "第1274已完成\n",
      "第1275已完成\n",
      "第1276已完成\n",
      "第1277已完成\n",
      "第1278已完成\n",
      "第1279已完成\n",
      "第1280已完成\n",
      "第1281已完成\n",
      "第1282已完成\n",
      "第1283已完成\n",
      "第1284已完成\n",
      "第1285已完成\n",
      "第1286已完成\n",
      "第1287已完成\n",
      "第1288已完成\n",
      "第1289已完成\n",
      "第1290已完成\n",
      "第1291已完成\n",
      "第1292已完成\n",
      "第1293已完成\n",
      "第1294已完成\n",
      "第1295已完成\n",
      "第1296已完成\n",
      "第1297已完成\n",
      "第1298已完成\n",
      "第1299已完成\n",
      "第1300已完成\n",
      "第1301已完成\n",
      "第1302已完成\n",
      "第1303已完成\n",
      "第1304已完成\n",
      "第1305已完成\n",
      "第1306已完成\n",
      "第1307已完成\n",
      "第1308已完成\n",
      "第1309已完成\n",
      "第1310已完成\n",
      "第1311已完成\n",
      "第1312已完成\n",
      "第1313已完成\n",
      "第1314已完成\n",
      "第1315已完成\n",
      "第1316已完成\n",
      "第1317已完成\n",
      "第1318已完成\n",
      "第1319已完成\n",
      "第1320已完成\n",
      "第1321已完成\n",
      "第1322已完成\n",
      "第1323已完成\n",
      "第1324已完成\n",
      "第1325已完成\n",
      "第1326已完成\n",
      "第1327已完成\n",
      "第1328已完成\n",
      "第1329已完成\n",
      "第1330已完成\n",
      "第1331已完成\n",
      "第1332已完成\n",
      "第1333已完成\n",
      "第1334已完成\n",
      "第1335已完成\n",
      "第1336已完成\n",
      "第1337已完成\n",
      "第1338已完成\n",
      "第1339已完成\n",
      "第1340已完成\n",
      "第1341已完成\n",
      "第1342已完成\n",
      "第1343已完成\n",
      "第1344已完成\n",
      "第1345已完成\n",
      "第1346已完成\n",
      "第1347已完成\n",
      "第1348已完成\n",
      "第1349已完成\n",
      "第1350已完成\n",
      "第1351已完成\n",
      "第1352已完成\n",
      "第1353已完成\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "data_x = np.zeros((1,224*224*3))\n",
    "data_label = np.zeros((1,1))\n",
    "def read_and_argumentation(data_x,data_label,label_id_name_dict):\n",
    "    k = random.sample(list(range(4794)),4793)\n",
    "    progress = 0\n",
    "    for i in k:\n",
    "        if i==0:\n",
    "            continue\n",
    "        try:\n",
    "            data_0 = cv2.imread('C:/Users/guyue/Desktop/train_data/img_'+str(i)+'.jpg')\n",
    "            data_0 = cv2.resize(data_0,(224,224),interpolation = cv2.INTER_CUBIC)\n",
    "            data_y = open('C:/Users/guyue/Desktop/train_data/img_'+str(i)+'.txt','r')\n",
    "            test = data_y.read()\n",
    "            if test=='':\n",
    "                data_y = np.array(test[-1],np.float32)\n",
    "            else:\n",
    "                data_y = np.array(test[-2:],np.float32)\n",
    "            data_x_i,data_y_i = argumentation(data_0,data_y)\n",
    "            data_x = np.vstack((data_x,data_x_i.reshape(-1,224*224*3)))\n",
    "            data_label = np.vstack((data_label,data_y_i))\n",
    "            progress+=1\n",
    "            print('第'+str(progress)+'已完成')\n",
    "        except:\n",
    "            continue\n",
    "    return (data_x/255.)[1:,:],data_label[1:]\n",
    "def argumentation(data_x,data_y):\n",
    "    data_x = data_x.reshape(224,224,3)\n",
    "    rot_mat = cv2.getRotationMatrix2D((data_x.shape[0]/2,data_x.shape[1]/2),90,1)\n",
    "    data_x_1 = cv2.warpAffine(data_0, rot_mat, (data_0.shape[1], data_0.shape[0]))\n",
    "    data_x_2 = cv2.GaussianBlur(data_x,(5,5),0)\n",
    "    data_y = np.vstack((data_y,data_y,data_y))\n",
    "    data_x = np.vstack((data_x.reshape(1,224*224*3),data_x_1.reshape(1,224*224*3),data_x_2.reshape(1,224*224*3)))\n",
    "    return data_x,data_y\n",
    "data_x_,data_y_ = read_and_argumentation(data_x,data_label,label_id_name_dict)\n",
    "data_all = np.hstack((data_x_,data_y_))\n",
    "np.random.shuffle(data_all)\n",
    "data_x,data_y = data_all[:,:-1],data_all[:,-1]\n",
    "label_id_name_dict = \\\n",
    "            {\n",
    "                \"0\": \"工艺品/仿唐三彩\",\n",
    "                \"1\": \"工艺品/仿宋木叶盏\",\n",
    "                \"2\": \"工艺品/布贴绣\",\n",
    "                \"3\": \"工艺品/景泰蓝\",\n",
    "                \"4\": \"工艺品/木马勺脸谱\",\n",
    "                \"5\": \"工艺品/柳编\",\n",
    "                \"6\": \"工艺品/葡萄花鸟纹银香囊\",\n",
    "                \"7\": \"工艺品/西安剪纸\",\n",
    "                \"8\": \"工艺品/陕历博唐妞系列\",\n",
    "                \"9\": \"景点/关中书院\",\n",
    "                \"10\": \"景点/兵马俑\",\n",
    "                \"11\": \"景点/南五台\",\n",
    "                \"12\": \"景点/大兴善寺\",\n",
    "                \"13\": \"景点/大观楼\",\n",
    "                \"14\": \"景点/大雁塔\",\n",
    "                \"15\": \"景点/小雁塔\",\n",
    "                \"16\": \"景点/未央宫城墙遗址\",\n",
    "                \"17\": \"景点/水陆庵壁塑\",\n",
    "                \"18\": \"景点/汉长安城遗址\",\n",
    "                \"19\": \"景点/西安城墙\",\n",
    "                \"20\": \"景点/钟楼\",\n",
    "                \"21\": \"景点/长安华严寺\",\n",
    "                \"22\": \"景点/阿房宫遗址\",\n",
    "                \"23\": \"民俗/唢呐\",\n",
    "                \"24\": \"民俗/皮影\",\n",
    "                \"25\": \"特产/临潼火晶柿子\",\n",
    "                \"26\": \"特产/山茱萸\",\n",
    "                \"27\": \"特产/玉器\",\n",
    "                \"28\": \"特产/阎良甜瓜\",\n",
    "                \"29\": \"特产/陕北红小豆\",\n",
    "                \"30\": \"特产/高陵冬枣\",\n",
    "                \"31\": \"美食/八宝玫瑰镜糕\",\n",
    "                \"32\": \"美食/凉皮\",\n",
    "                \"33\": \"美食/凉鱼\",\n",
    "                \"34\": \"美食/德懋恭水晶饼\",\n",
    "                \"35\": \"美食/搅团\",\n",
    "                \"36\": \"美食/枸杞炖银耳\",\n",
    "                \"37\": \"美食/柿子饼\",\n",
    "                \"38\": \"美食/浆水面\",\n",
    "                \"39\": \"美食/灌汤包\",\n",
    "                \"40\": \"美食/烧肘子\",\n",
    "                \"41\": \"美食/石子饼\",\n",
    "                \"42\": \"美食/神仙粉\",\n",
    "                \"43\": \"美食/粉汤羊血\",\n",
    "                \"44\": \"美食/羊肉泡馍\",\n",
    "                \"45\": \"美食/肉夹馍\",\n",
    "                \"46\": \"美食/荞面饸饹\",\n",
    "                \"47\": \"美食/菠菜面\",\n",
    "                \"48\": \"美食/蜂蜜凉粽子\",\n",
    "                \"49\": \"美食/蜜饯张口酥饺\",\n",
    "                \"50\": \"美食/西安油茶\",\n",
    "                \"51\": \"美食/贵妃鸡翅\",\n",
    "                \"52\": \"美食/醪糟\",\n",
    "                \"53\": \"美食/金线油塔\"\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-22T10:26:02.447513Z",
     "start_time": "2019-11-22T10:26:02.441530Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-22T10:50:44.391565Z",
     "start_time": "2019-11-22T10:50:44.371618Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class nn:\n",
    "    def __init__(self,data_x,data_y,train_layer_num=-2):\n",
    "        '''\n",
    "        data_x:数据，增强后，且大小为[-1,224*224*3]\n",
    "        data_x:标签，大小为[-1,1]\n",
    "        image_shape = [224,224,3]\n",
    "        train_layer_num = 欲训练迁移模型参数层数，使用负值，默认为-2，即只训练全连接层与分类层\n",
    "        '''\n",
    "        self.model = tf.keras.applications.MobileNetV2(input_shape = (224,224,3),include_top=False,weights = 'imagenet')\n",
    "        self.data_x = data_x\n",
    "        self.data_y = data_y\n",
    "        self.class_num  = 53\n",
    "        self.test_accuracy = 0.\n",
    "        self.train_layer_num = train_layer_num\n",
    "    def build_model(self):\n",
    "        self.model = tf.keras.Sequential([\n",
    "            self.model,\n",
    "            tf.keras.layers.GlobalAveragePooling2D(),\n",
    "            tf.keras.layers.Dense(2048,activation='relu'),\n",
    "            tf.keras.layers.Dense(self.class_num,activation='softmax')\n",
    "        ])\n",
    "        for layer in self.model.layers[:self.train_layer_num]:\n",
    "            layer.trainable = False\n",
    "        self.model.compile(optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "                           loss='sparse_categorical_crossentropy',\n",
    "                           metrics=['accuracy'])\n",
    "        self.model.summary()\n",
    "    def onehot(self):\n",
    "        data_y_onehot = np.zeros((self.data_y.shape[0],self.class_num))\n",
    "        for i in range(data_y_onehot.shape[0]):\n",
    "            data_y_onehot[i,self.data_y[i]]=0\n",
    "        return data_y_onehot\n",
    "    def train_split_data(self):\n",
    "        data_x_train,data_x_test,data_y_train,data_y_test = train_test_split(self.data_x,self.onehot(),test_size=0.3)\n",
    "        return data_x_train,data_x_test,data_y_train,data_y_test\n",
    "    def main(self):\n",
    "        data_x_train,data_x_test,data_y_train,data_y_test = self.train_split_data()\n",
    "        data_x_train = tf.reshape(tf.convert_to_tensor(data_x_train,tf.float32),[-1,224,224,3])\n",
    "        data_x_test = tf.reshape(tf.convert_to_tensor(data_x_test,tf.float32),[-1,224,224,3])\n",
    "        data_y_train = tf.convert_to_tensor(data_y_train,tf.float32)\n",
    "        data_y_test = tf.convert_to_tensor(data_y_test,tf.float32)\n",
    "        self.model.fit(data_x_train,data_y_train,epochs=50)\n",
    "        self.test_accuracy = self.evaluate(data_x_test,data_y_test)\n",
    "compute = nn(data_x,data_y)\n",
    "compute.build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-22T10:55:32.060871Z",
     "start_time": "2019-11-22T10:55:32.052892Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[67]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(list(range(1,91)),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-22T11:01:04.070840Z",
     "start_time": "2019-11-22T11:01:04.064856Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "np.random.shuffle(np.arange(9).reshape(3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
